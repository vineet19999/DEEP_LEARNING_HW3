import logging
import os
import torch

valkey='test'
TrustRemoteCode=True

#creates a logger for the current module
logger = logging.getLogger(__name__)

def get_device(gpuid='0', useamp=False):
    if torch.cuda.is_available():
        device = torch.device('cuda:'+str(gpuid))  # CUDA GPU 0
    elif torch.backends.mps.is_available():
        device = torch.device("mps")
        useamp = False
    else:
        device = torch.device("cpu")
        useamp = False
    return device, useamp

def deviceenv_set(USE_HPC, data_path=""):
    if USE_HPC:
        #https://huggingface.co/docs/transformers/installation#offline-mode
        #HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1
        mycache_dir=data_path #"/data/cmpe249-fa23/Huggingfacecache"
        #os.environ['TRANSFORMERS_CACHE'] = mycache_dir
        os.environ['HF_HOME'] = mycache_dir
        os.environ['HF_DATASETS_CACHE'] = mycache_dir
        #os.environ['HF_EVALUATE_OFFLINE'] = "1"
        #os.environ['HF_DATASETS_OFFLINE'] = "1"
        #os.environ['TRANSFORMERS_OFFLINE'] = "1"
        os.environ['http_proxy'] = "http://172.16.1.2:3128"
        os.environ['HTTP_PROXY'] = "http://172.16.1.2:3128"
        os.environ['https_proxy'] = "http://172.16.1.2:3128"
        os.environ['HTTPS_PROXY'] = "http://172.16.1.2:3128"
        trainoutput="/data/cmpe249-fa23/trainoutput/huggingface"
        #taskname=args.traintag #"eli5asksciencemodeling"
    else:
        if os.path.exists(data_path):
            mycache_dir=data_path
            os.environ['HF_HOME'] = mycache_dir
            #os.environ['HF_DATASETS_CACHE'] = mycache_dir
        elif os.environ.get('HF_HOME') is not None:
            mycache_dir=os.environ['HF_HOME']
            #os.environ['HF_DATASETS_CACHE'] = mycache_dir
        else:
            mycache_dir="./data/"
            os.environ['HF_HOME'] = mycache_dir
            #os.environ['HF_DATASETS_CACHE'] = mycache_dir
        # mycache_dir=os.path.join('D:',os.sep, 'Cache','huggingface')
        
        print("HF_HOME:", os.environ['HF_HOME'])
        #print("HF_DATASETS_CACHE:", os.environ['HF_DATASETS_CACHE'])
        # os.environ['HF_DATASETS_CACHE'] = mycache_dir
        # if os.environ.get('HF_HOME') is None:
        #     mycache_dir=args.data_path
        #     os.environ['HF_HOME'] = mycache_dir
        #     os.environ['HF_DATASETS_CACHE'] = mycache_dir
        # else:
        #     print("HF_HOME:", os.environ['HF_HOME'])
        #     mycache_dir=os.environ['HF_HOME']
        #trainoutput=args.outputdir #"./output"
        #taskname=args.traintag #taskname="eli5asksciencemodeling"
    
    return mycache_dir

#pip install moviepy
#pip install youtube_dl
#pip install yt-dlp #https://cheat.sh/yt-dlp
import os
import moviepy.editor as mp 
def download_youtube(clip_url, outputfolder='./output'):
    # Download the clip as mp4 & rename it for usability
    #os.system('youtube-dl -F {}'.format(clip_url))
    #os.system('youtube-dl {} --recode-video mp4'.format(clip_url))
    filepath = str(os.path.join(outputfolder,'clip.mp4'))
    os.system(f'yt-dlp -o {filepath} {clip_url}')
    #os.system(f'mv *.mp4 {filepath}')
    return filepath

#pip install youtube-transcript-api
from youtube_transcript_api import YouTubeTranscriptApi
#from youtube_transcript_api.formatters import JSONFormatter
def test_youtube_transcript(video_id, outputfolder='./output'):
    #transcription = YouTubeTranscriptApi.get_transcripts([video_id], languages=['zh-CN', 'en'])

    # retrieve the available transcripts
    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
    # iterate over all available transcripts
    for transcript in transcript_list:

        # the Transcript object provides metadata properties
        print(
            transcript.video_id,
            transcript.language,
            transcript.language_code,
            # whether it has been manually created or generated by YouTube
            transcript.is_generated,
            # whether this transcript can be translated or not
            transcript.is_translatable,
            # a list of languages the transcript can be translated to
            #transcript.translation_languages, #list of 'language' and 'language_code'
        )

        # fetch the actual transcript data
        #fetched = transcript.fetch()
        #print(fetched)

        # translating the transcript will return another transcript object
        #print(transcript.translate('en').fetch())
    
    # you can also directly filter for the language you are looking for, using the transcript list
    transcript = transcript_list.find_transcript(['zh-CN', 'en'])  

    # or just filter for manually created transcripts  
    transcript = transcript_list.find_manually_created_transcript(['zh-CN', 'en'])  

    # or automatically generated ones  
    transcript = transcript_list.find_generated_transcript(['zh-CN', 'en'])

import json
def save_json(json_formatted, name, outputfolder='./output'):
    # Now we can write it out to a file.
    filepath = os.path.join(outputfolder, name+'.json')
    # with open(filepath, 'w', encoding='utf-8') as json_file:
    #     json_file.write(json_formatted)
    # Convert and write JSON object to file
    with open(filepath, "w") as outfile: 
        json.dump(json_formatted, outfile)
    return filepath

#write a python to load a json file into dictionary from json file
def load_json(filepath):
    #filepath = name #os.path.join(folder, name)
    with open(filepath, 'r') as json_file:
        json_data = json.load(json_file)
    return json_data


import pandas as pd 
def download_youtube_transcript(video_id, languagecodelist=['zh-CN', 'en'], outputfolder='./output'):
    # retrieve the available transcripts
    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
    # iterate over all available transcripts
    for transcript in transcript_list:
        result_dict = {}
        language_code = transcript.language_code
        result_dict['video_id'] = transcript.video_id
        result_dict['language'] = transcript.language
        result_dict['language_code'] = language_code
        result_dict['is_generated'] = transcript.is_generated # whether it has been manually created or generated by YouTube
        result_dict['is_translatable'] = transcript.is_translatable
        
        if language_code in languagecodelist:
            if transcript.is_generated:
                filename = os.path.join(outputfolder, language_code+'_generated.csv')
            else:
                filename = os.path.join(outputfolder, language_code+'.csv')
            fetched = transcript.fetch()
            #print(fetched)
            df = pd.DataFrame.from_records(fetched)
            print(df.head())
            df.to_csv(filename, index=False)
            result_dict['csvpath'] = filename
            save_json(result_dict, name=language_code+'_info', outputfolder=outputfolder)

    # # or just filter for manually created transcripts 
    # for language_code in languagecodelist:
    #     transcript = transcript_list.find_manually_created_transcript([language_code])  
    #     if transcript is not None:
    #         fetched = transcript.fetch()
    #         #print(fetched)
    #         filename = os.path.join(outputfolder, video_id+'_'+language_code+'.csv')
    #         df = pd.DataFrame.from_records(fetched)
    #         print(df.head())
    #         df.to_csv(filename, index=False)
    
def video2audio(filepath="clip.mp4", start=1, end=20, outputfolder='./output', audiofilename='audio.mp3'):
    clip = mp.VideoFileClip(filepath)
    print("clip duration:", clip.duration)
    if end > 0:
        end = min(clip.duration, end)
    else:
        end = clip.duration
    sub_clip = clip.subclip(start,end)
    audio_clip = sub_clip.audio
    audio_clip.write_audiofile(os.path.join(outputfolder, audiofilename))
    audio_clip.close()
    clip.close()



def clip_video(filepath="clip.mp4", start=1, end=20, step=5, outputfolder='./output'):
    clip = mp.VideoFileClip(filepath)
    print("clip duration:", clip.duration)
    if end > 0:
        end = min(clip.duration, end)
    else:
        end = clip.duration

    clip_paths = []
    # Extract Audio-only from mp4
    for i in range(start, int(end), step):
        sub_end = min(i+10, end)
        sub_clip = clip.subclip(i,sub_end)
        audiopath=os.path.join(outputfolder, "audio_" + str(i) + ".mp3")
        sub_clip.audio.write_audiofile(audiopath)
        clip_paths.append(audiopath)
    return clip_paths



if __name__ == "__main__":
    clip_url = "https://youtu.be/Sk1y1auK1xc" #"https://www.youtube.com/watch?v=yzm4gpAKrBk"
    video_id = "Sk1y1auK1xc"
    outputfolder = "data/audio"
    os.makedirs(outputfolder, exist_ok = True)
    outputfolder = os.path.join(outputfolder, video_id)
    os.makedirs(outputfolder, exist_ok = True)

    video2audio(filepath=os.path.join(outputfolder, "clip.mp4"), start=0, end=-1, outputfolder=outputfolder, audiofilename='audio.mp3')

    #test_youtube_transcript(video_id, outputfolder=outputfolder)
    download_youtube_transcript(video_id, languagecodelist=['zh-CN', 'en'], outputfolder=outputfolder)

    filepath = download_youtube(clip_url, outputfolder=outputfolder)
    
    clip_paths = clip_video(filepath=filepath, start=0, end=15, step=5, outputfolder=outputfolder)
    print(clip_paths)